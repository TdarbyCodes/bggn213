---
title: "Lab 9: Mini Project"
author: "Taylor Darby"
date: "10/27/2021"
output: pdf_document
---

# 1. Exploratory data analysis

## Preparing the data

```{r}
# Save input data file into Project directory
fna.data <- "WisconsinCancer.csv"

# read the csv file
wisc.d <- read.csv(fna.data, row.names = 1)

# examine input data
head(wisc.d)

# **WARNING** determined there was an issue with the file. A last empty column was inserted and needs to be removed.

ncol(wisc.d)
# There are 32 columns so we will remove the last column
wisc.df <- wisc.d[,-32]

ncol(wisc.df)
```

```{r}
# Remove the first column of the dataset because essentially this is our "answer" in our unsupervised analysis

wisc.data <- wisc.df[,-1]

# Setup a separate vector with data from the "diagnosis" column only ('as.factor()' function makes using the data easier later)
diagnosis <- as.factor(wisc.df$diagnosis)
diagnosis
```

## Exploratory data analysis

> **Q1.** How many observations are in this dataset?

### There are 569 observations in this dataset.

```{r}
nrow(wisc.data)
```

> **Q2.** How many of the observations have a malignant diagnosis?

### There are 212 malignant diagnosis.

```{r}
# generate a table of the "diagnosis" data to sum each categorical value
table(diagnosis)
```

> **Q3.** How many variables/features in the data are suffixed with '_mean'?

### There are 10 variables/features suffixed with '_mean'

```{r}
# use grep to determine where the pattern '_mean" occurs and use 'length' to count how many times the patter occurs

length(grep("_mean", colnames(wisc.df)))
```

# 2. Principal Component Analysis

## Performing PCA

```{r}
# Check the columns of the 'wisc.data' to determine if the data should be scaled

colMeans(wisc.data)

apply(wisc.data, 2, sd)
```

```{r}
# Perform PCA on wisc.data by completing the following code --> determined data needs to be scaled
wisc.pr <- prcomp(wisc.data, scale. = TRUE)
summary(wisc.pr)
```

> **Q4.** From your results, what proportion of the original variance is captured by the first principal components (PC1)?

### Proportion of Variance PC1 = 0.4427

> **Q5.** How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

### Three. In PC3 at least 70% of the original variance is described

> **Q6.** How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

### Seven. In PC7 at least 70% of the original variance is described

## Interpreting PCA results

```{r}
# Create a biplot of the PCA data (wisc.pr)
biplot(wisc.pr)
```

> **Q7.** What stands out to you about this plot? Is it easy or difficult to understand? Why?

### There are way too many datapoints to be able to understand what is going on.

Let's find a solution to this:
```{r}
# Generate a more standard scatter plot of each observation along principal components 1 and 2 and color the points by the diagnosis.

plot(wisc.pr$x, col=diagnosis,
     xlab="PC1", ylab="PC2")
```

> **Q8.** Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

### The plots look very similar but the PC3 values are shifted down a bit.

```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[,c("PC1","PC3")], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```

Let's try in **ggplot**
```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

## Variance explained

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```
Calculate the variance explained by each principal component by dividing by the total variance explained of all principal components.

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

## **OPTIONAL:** There are quite a few CRAN packages that are helpful for PCA. This includes the factoextra package. Feel free to explore this package. 

```{r}
# install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

## Communicating PCA results

> **Q9.** For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
# call the first column of row "concave.points_mean" from the "rotation" dataset of 'wisc.pr'
wisc.pr$rotation["concave.points_mean",1]
```

> **Q10.** What is the minimum number of principal components required to explain 80% of the variance of the data?

There are four PCs with less than 80% variance of the data. That means it takes 5 PCs to explain 80% or more of the variance of the data.
```{r}
var <- summary(wisc.pr)
sum(var$importance[3,] < 0.8)

```

# 3. Hierarchical clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```


```{r}
# Calculate the (Euclidean) distances between all pairs of observations in the new scaled dataset and assign the result to data.dist.
data.dist <-  dist(data.scaled)
```

```{r}
# Create a hierarchical clustering model using complete linkage. Manually specify the method argument to 'hclust()' and assign the results to 'wisc.hclust'.
wisc.hclust <- hclust(data.dist, method = "complete")
```


## Results of hierarchical clustering

> **Q11.** Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

### At about a height of 19 the clustering model has 4 clusters.

```{r}
plot(wisc.hclust)
abline(h=19 , col="red", lty=2)
```

Use 'cutree()' to cut the tree so that it has 4 clusters. Assign the output to the variable wisc.hclust.clusters.

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
table(wisc.hclust.clusters, diagnosis)

```

> **Q12.** Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?



## Using different methods

> **Q13.** Which method gives your favorite results for the same 'data.dist' dataset? Explain your reasoning.





